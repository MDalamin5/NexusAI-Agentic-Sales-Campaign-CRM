{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd0dc3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56b25c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6dc9bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af218bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Company Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Michael</td>\n",
       "      <td>Scott</td>\n",
       "      <td>m.scott@dundermifflin.com</td>\n",
       "      <td>Dunder Mifflin</td>\n",
       "      <td>Regional Manager</td>\n",
       "      <td>Paper &amp; Distribution</td>\n",
       "      <td>10-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bruce</td>\n",
       "      <td>Wayne</td>\n",
       "      <td>bruce@waynetech.com</td>\n",
       "      <td>Wayne Enterprises</td>\n",
       "      <td>Chairman</td>\n",
       "      <td>Conglomerate</td>\n",
       "      <td>10000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Harvey</td>\n",
       "      <td>Specter</td>\n",
       "      <td>h.specter@pearson-hardman.com</td>\n",
       "      <td>Pearson Hardman</td>\n",
       "      <td>Senior Partner</td>\n",
       "      <td>Law</td>\n",
       "      <td>200-500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   First Name Last Name                          Email            Company  \\\n",
       "2     Michael     Scott      m.scott@dundermifflin.com     Dunder Mifflin   \n",
       "10      Bruce     Wayne            bruce@waynetech.com  Wayne Enterprises   \n",
       "19     Harvey   Specter  h.specter@pearson-hardman.com    Pearson Hardman   \n",
       "\n",
       "           Job Title              Industry Company Size  \n",
       "2   Regional Manager  Paper & Distribution        10-50  \n",
       "10          Chairman          Conglomerate       10000+  \n",
       "19    Senior Partner                   Law      200-500  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"lead.csv\")\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec1937dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # --- 1. INPUT DATA ---\n",
    "    lead_data: dict  # Raw data from CSV (Name, Email, Company, Job Title, etc.)\n",
    "    \n",
    "    # --- 2. QUALIFICATION (From Scorer Agent) ---\n",
    "    priority: str          # \"High\", \"Medium\", \"Low\"\n",
    "    priority_score: int    # 1 to 10 (Useful for sorting the final CSV)\n",
    "    priority_reason: str   # The \"Why\" behind the score\n",
    "    \n",
    "    # --- 3. ENRICHMENT (From Persona Agent) ---\n",
    "    persona: str           # e.g., \"The Data-Driven Executive\"\n",
    "    persona_description: str # Brief profile of their pain points\n",
    "    \n",
    "    # --- 4. OUTREACH (From Drafter Agent) ---\n",
    "    email_subject: str\n",
    "    email_body: str        # The personalized HTML/Text body\n",
    "    \n",
    "    # --- 5. SIMULATION (From Response Agents) ---\n",
    "    simulated_reply: Optional[str]   # What the AI thinks they would say back\n",
    "    response_category: Optional[str] # \"Interested\", \"Not Interested\", \"Auto-reply\"\n",
    "    \n",
    "    # --- 6. EXECUTION STATUS ---\n",
    "    status: str            # \"Sent\", \"Failed\", or \"Pending\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae9ba7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq # Switch later\n",
    "from prompts import LEAD_SCORER_SYSTEM_PROMPT, PERSONA_ENRICHER_SYSTEM_PROMPT\n",
    "from schema import LeadScore\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def get_scorer_agent():\n",
    "    # Model Setup\n",
    "    # llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0) \n",
    "    # To switch to Groq later:\n",
    "    llm = ChatGroq(model=\"qwen/qwen3-32b\", temperature=0)\n",
    "    \n",
    "    # Bind the structured output schema to the LLM\n",
    "    structured_llm = llm.with_structured_output(LeadScore)\n",
    "    \n",
    "    return structured_llm\n",
    "\n",
    "# --- THE NODE FUNCTION FOR LANGGRAPH ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a3f24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lead_scorer_node(state: AgentState):\n",
    "    lead_data = state[\"lead_data\"]\n",
    "    \n",
    "    # Format the user message with Lead details\n",
    "    user_message = f\"Lead Data: {lead_data}\"\n",
    "    \n",
    "    # Invoke the agent\n",
    "    scorer_agent = get_scorer_agent()\n",
    "    result = scorer_agent.invoke([\n",
    "        (\"system\", LEAD_SCORER_SYSTEM_PROMPT),\n",
    "        (\"human\", user_message)\n",
    "    ])\n",
    "    \n",
    "    # Update the LangGraph State\n",
    "    return {\n",
    "        \"priority\": result.priority,\n",
    "        \"priority_score\": result.score, # Added to state for more detail\n",
    "        \"priority_reason\": result.reasoning\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859e837c",
   "metadata": {},
   "source": [
    "## **Test the lead-scorer agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12218f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'priority': 'Low', 'priority_score': 3, 'priority_reason': 'The lead is a Jr. AI Engineer at a mid-sized AI Solutions company. Junior roles typically lack decision-making authority, and while the industry is relevant, the position does not indicate high budget control or partnership potential.'}\n"
     ]
    }
   ],
   "source": [
    "# Create a dummy row from your DF\n",
    "sample_lead = df.iloc[1].to_dict() # Elon Musk\n",
    "\n",
    "# Create initial state\n",
    "test_state = {\n",
    "    \"lead_data\": sample_lead,\n",
    "    \"priority\": \"\",\n",
    "    \"priority_score\": 0,\n",
    "    \"priority_reason\": \"\"\n",
    "}\n",
    "\n",
    "# Run node\n",
    "updated_state = lead_scorer_node(test_state)\n",
    "print(updated_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a13cc19",
   "metadata": {},
   "source": [
    "## **Persona Enricher Node**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f40eeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from schema import PersonaEnrichment\n",
    "\n",
    "def get_persona_agent():\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7) # Slightly higher temperature for \"Creativity\"\n",
    "    structured_llm = llm.with_structured_output(PersonaEnrichment)\n",
    "    return structured_llm\n",
    "\n",
    "# --- THE NODE FUNCTION ---\n",
    "def persona_enricher_node(state: AgentState):\n",
    "    lead_data = state[\"lead_data\"]\n",
    "    \n",
    "    user_message = f\"Lead Data: {lead_data}\"\n",
    "    \n",
    "    agent = get_persona_agent()\n",
    "    result = agent.invoke([\n",
    "        (\"system\", PERSONA_ENRICHER_SYSTEM_PROMPT),\n",
    "        (\"human\", user_message)\n",
    "    ])\n",
    "    \n",
    "    # Update the LangGraph State\n",
    "    return {\n",
    "        \"persona\": result.persona,\n",
    "        \"persona_description\": result.persona_description\n",
    "        # Note: You can also store key_motivations if you add it to AgentState\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da2f93f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priority: Low\n",
      "Persona: The Efficiency Champion\n",
      "Description: A result-driven manager focused on optimizing team performance and resource allocation. They are constantly seeking ways to enhance productivity while minimizing costs and ensuring staff satisfaction in a competitive market.\n"
     ]
    }
   ],
   "source": [
    "# 1. Reset your test state\n",
    "test_state = {\n",
    "    \"lead_data\": df.iloc[2].to_dict(), # Using the Jr. AI Engineer row\n",
    "    \"priority\": \"\",\n",
    "    \"priority_score\": 0,\n",
    "    \"priority_reason\": \"\",\n",
    "    \"persona\": \"\",\n",
    "    \"persona_description\": \"\"\n",
    "}\n",
    "\n",
    "# 2. Run Scorer and UPDATE the dictionary (Don't overwrite it)\n",
    "scorer_results = lead_scorer_node(test_state)\n",
    "test_state.update(scorer_results) \n",
    "\n",
    "# Now test_state has BOTH lead_data AND the priority results\n",
    "\n",
    "# 3. Now run the Enricher\n",
    "persona_results = persona_enricher_node(test_state)\n",
    "test_state.update(persona_results)\n",
    "\n",
    "# 4. Check the results\n",
    "print(f\"Priority: {test_state['priority']}\")\n",
    "print(f\"Persona: {test_state['persona']}\")\n",
    "print(f\"Description: {test_state['persona_description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4868a9",
   "metadata": {},
   "source": [
    "## **Draft a ostrich Email**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24ac2436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import OUTREACH_DRAFTER_SYSTEM_PROMPT\n",
    "from schema import EmailDraft\n",
    "\n",
    "def get_drafter_agent():\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.8) # Higher temperature for creative writing\n",
    "    structured_llm = llm.with_structured_output(EmailDraft)\n",
    "    return structured_llm\n",
    "\n",
    "# --- THE NODE FUNCTION ---\n",
    "def outreach_drafter_node(state: AgentState):\n",
    "    lead_data = state[\"lead_data\"]\n",
    "    priority = state[\"priority\"]\n",
    "    persona = state[\"persona\"]\n",
    "    \n",
    "    # Combine context for the agent\n",
    "    context = f\"\"\"\n",
    "    Lead: {lead_data['First Name']} {lead_data['Last Name']}\n",
    "    Role: {lead_data['Job Title']} at {lead_data['Company']}\n",
    "    Priority Level: {priority}\n",
    "    Buyer Persona: {persona}\n",
    "    \"\"\"\n",
    "    \n",
    "    agent = get_drafter_agent()\n",
    "    result = agent.invoke([\n",
    "        (\"system\", OUTREACH_DRAFTER_SYSTEM_PROMPT),\n",
    "        (\"human\", f\"Draft a personalized email for this lead:\\n{context}\")\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"email_subject\": result.subject,\n",
    "        \"email_body\": result.body\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dccc601a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Quick question about streamlining Dunder Mifflin's processes\n",
      "------------------------------\n",
      "Hi Michael,<br><br>As the Regional Manager at Dunder Mifflin, I know you're always on the lookout for ways to boost efficiency. That's why I wanted to share how NexusAI can help you automate tedious tasks, saving your team valuable time and reducing manual work.<br><br>Open to a 5-minute chat? I'd love to explore how we can support your goals.<br><br>Best,<br>NexusAI Growth Team\n"
     ]
    }
   ],
   "source": [
    "# Continue from your previous 'test_state'\n",
    "drafter_results = outreach_drafter_node(test_state)\n",
    "test_state.update(drafter_results)\n",
    "\n",
    "print(f\"Subject: {test_state['email_subject']}\")\n",
    "print(\"-\" * 30)\n",
    "print(test_state['email_body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebd9f2a",
   "metadata": {},
   "source": [
    "## **SMTP Sender Node**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b25d5bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "def sender_node(state: AgentState):\n",
    "    \"\"\"\n",
    "    Physically sends the drafted email to MailHog via SMTP.\n",
    "    \"\"\"\n",
    "    # 1. Get data from state\n",
    "    lead_email = state[\"lead_data\"][\"Email\"]\n",
    "    subject = state[\"email_subject\"]\n",
    "    body = state[\"email_body\"]\n",
    "    \n",
    "    # 2. Setup SMTP Config\n",
    "    # If running notebook locally: use \"localhost\"\n",
    "    # If running inside Docker later: use \"mailhog\"\n",
    "    SMTP_HOST = \"localhost\" \n",
    "    SMTP_PORT = 1025\n",
    "    SENDER_EMAIL = \"outreach@nexusai.com\"\n",
    "\n",
    "    # 3. Create the MIME Message\n",
    "    message = MIMEMultipart()\n",
    "    message[\"From\"] = SENDER_EMAIL\n",
    "    message[\"To\"] = lead_email\n",
    "    message[\"Subject\"] = subject\n",
    "    \n",
    "    # Use \"html\" type because our drafter agent uses <br> tags\n",
    "    message.attach(MIMEText(body, \"html\"))\n",
    "\n",
    "    # 4. Attempt to send\n",
    "    try:\n",
    "        with smtplib.SMTP(SMTP_HOST, SMTP_PORT) as server:\n",
    "            server.sendmail(SENDER_EMAIL, [lead_email], message.as_string())\n",
    "        \n",
    "        print(f\"üìß Email successfully delivered to: {lead_email}\")\n",
    "        return {\"status\": \"Sent\"}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå SMTP Error: {e}\")\n",
    "        return {\"status\": f\"Failed: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ced9e1",
   "metadata": {},
   "source": [
    "## **Test the mail**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "081139e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìß Email successfully delivered to: m.scott@dundermifflin.com\n",
      "Final Status: Sent\n"
     ]
    }
   ],
   "source": [
    "# Continue from your test_state (which has the subject and body from the previous cell)\n",
    "sender_results = sender_node(test_state)\n",
    "test_state.update(sender_results)\n",
    "\n",
    "print(f\"Final Status: {test_state['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c05410a",
   "metadata": {},
   "source": [
    "## **Feedback Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2be1e644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import RESPONSE_SIMULATOR_SYSTEM_PROMPT\n",
    "from schema import SimulatedResponse\n",
    "\n",
    "def get_simulator_agent():\n",
    "    # Use a higher temperature (0.9) to get diverse types of replies\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.9) \n",
    "    structured_llm = llm.with_structured_output(SimulatedResponse)\n",
    "    return structured_llm\n",
    "\n",
    "# --- THE NODE FUNCTION ---\n",
    "def response_simulator_node(state: AgentState):\n",
    "    lead_data = state[\"lead_data\"]\n",
    "    persona = state[\"persona\"]\n",
    "    outreach_email = state[\"email_body\"]\n",
    "    \n",
    "    context = f\"\"\"\n",
    "    Lead: {lead_data['First Name']} {lead_data['Last Name']}\n",
    "    Persona: {persona}\n",
    "    Email Received: {outreach_email}\n",
    "    \"\"\"\n",
    "    \n",
    "    agent = get_simulator_agent()\n",
    "    result = agent.invoke([\n",
    "        (\"system\", RESPONSE_SIMULATOR_SYSTEM_PROMPT),\n",
    "        (\"human\", f\"Write a reply to this email based on your persona:\\n{context}\")\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"simulated_reply\": result.reply_text\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2912a872",
   "metadata": {},
   "source": [
    "## **Simulate a reply of the email**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2516a426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Name: Michael\n",
      "Simulated Reply: Thanks for reaching out. I'm always looking for ways to improve efficiency‚Äîlet's schedule that chat for next week.\n"
     ]
    }
   ],
   "source": [
    "# Continue from your test_state\n",
    "simulator_results = response_simulator_node(test_state)\n",
    "test_state.update(simulator_results)\n",
    "\n",
    "print(f\"Lead Name: {test_state['lead_data']['First Name']}\")\n",
    "print(f\"Simulated Reply: {test_state['simulated_reply']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf7a068",
   "metadata": {},
   "source": [
    "## **Categorizer agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f9c38ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import RESPONSE_CATEGORIZER_SYSTEM_PROMPT\n",
    "from schema import ResponseCategory\n",
    "\n",
    "def get_categorizer_agent():\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0) # Zero temperature for consistent labeling\n",
    "    structured_llm = llm.with_structured_output(ResponseCategory)\n",
    "    return structured_llm\n",
    "\n",
    "# --- THE NODE FUNCTION ---\n",
    "def response_categorizer_node(state: AgentState):\n",
    "    reply = state[\"simulated_reply\"]\n",
    "    \n",
    "    agent = get_categorizer_agent()\n",
    "    result = agent.invoke([\n",
    "        (\"system\", RESPONSE_CATEGORIZER_SYSTEM_PROMPT),\n",
    "        (\"human\", f\"Categorize this lead response:\\n{reply}\")\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"response_category\": result.category\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a840c092",
   "metadata": {},
   "source": [
    "## **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6e94c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reply: Thanks for reaching out. I'm always looking for ways to improve efficiency‚Äîlet's schedule that chat for next week.\n",
      "FINAL CATEGORY: Interested\n"
     ]
    }
   ],
   "source": [
    "# Continue from your test_state\n",
    "categorizer_results = response_categorizer_node(test_state)\n",
    "test_state.update(categorizer_results)\n",
    "\n",
    "print(f\"Reply: {test_state['simulated_reply']}\")\n",
    "print(f\"FINAL CATEGORY: {test_state['response_category']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006d33a6",
   "metadata": {},
   "source": [
    "## **Its my Agent state for one lead**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9e10c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lead_data': {'First Name': 'Michael',\n",
       "  'Last Name': 'Scott',\n",
       "  'Email': 'm.scott@dundermifflin.com',\n",
       "  'Company': 'Dunder Mifflin',\n",
       "  'Job Title': 'Regional Manager',\n",
       "  'Industry': 'Paper & Distribution',\n",
       "  'Company Size': '10-50'},\n",
       " 'priority': 'Low',\n",
       " 'priority_score': 3,\n",
       " 'priority_reason': 'The lead is a Regional Manager at a small Paper & Distribution company with 10-50 employees. The industry is unrelated to AI/automation, and the company size suggests limited budget potential.',\n",
       " 'persona': 'The Efficiency Champion',\n",
       " 'persona_description': 'A result-driven manager focused on optimizing team performance and resource allocation. They are constantly seeking ways to enhance productivity while minimizing costs and ensuring staff satisfaction in a competitive market.',\n",
       " 'email_subject': \"Quick question about streamlining Dunder Mifflin's processes\",\n",
       " 'email_body': \"Hi Michael,<br><br>As the Regional Manager at Dunder Mifflin, I know you're always on the lookout for ways to boost efficiency. That's why I wanted to share how NexusAI can help you automate tedious tasks, saving your team valuable time and reducing manual work.<br><br>Open to a 5-minute chat? I'd love to explore how we can support your goals.<br><br>Best,<br>NexusAI Growth Team\",\n",
       " 'status': 'Sent',\n",
       " 'simulated_reply': \"Thanks for reaching out. I'm always looking for ways to improve efficiency‚Äîlet's schedule that chat for next week.\",\n",
       " 'response_category': 'Interested'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6fd723",
   "metadata": {},
   "source": [
    "## **Build the Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49f6f9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Initialize the Graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# 1. Add Nodes\n",
    "workflow.add_node(\"scorer\", lead_scorer_node)\n",
    "workflow.add_node(\"enricher\", persona_enricher_node)\n",
    "workflow.add_node(\"drafter\", outreach_drafter_node)\n",
    "workflow.add_node(\"sender\", sender_node)\n",
    "workflow.add_node(\"simulator\", response_simulator_node)\n",
    "workflow.add_node(\"categorizer\", response_categorizer_node)\n",
    "\n",
    "# 2. Define Edges (The Flow)\n",
    "workflow.add_edge(START, \"scorer\")\n",
    "workflow.add_edge(\"scorer\", \"enricher\")\n",
    "workflow.add_edge(\"enricher\", \"drafter\")\n",
    "workflow.add_edge(\"drafter\", \"sender\")\n",
    "workflow.add_edge(\"sender\", \"simulator\")\n",
    "workflow.add_edge(\"simulator\", \"categorizer\")\n",
    "workflow.add_edge(\"categorizer\", END)\n",
    "\n",
    "# 3. Compile the Graph\n",
    "nexus_app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b4a05fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import CAMPAIGN_SUMMARY_PROMPT\n",
    "\n",
    "def generate_campaign_report(results_list):\n",
    "    # Prepare the data for the LLM\n",
    "    summary_data = \"\"\n",
    "    for r in results_list:\n",
    "        summary_data += f\"- Lead: {r['lead_data']['Email']}, Priority: {r['priority']}, Category: {r['response_category']}\\n\"\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        (\"system\", CAMPAIGN_SUMMARY_PROMPT),\n",
    "        (\"human\", f\"Review these campaign results and write a summary report:\\n\\n{summary_data}\")\n",
    "    ])\n",
    "    \n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33cf5273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ NexusAI: Processing 20 leads...\n",
      "[1/20] Processing elon@spacex.com...\n",
      "üìß Email successfully delivered to: elon@spacex.com\n",
      "[2/20] Processing nsuer.alamin@gmail.com...\n",
      "üìß Email successfully delivered to: nsuer.alamin@gmail.com\n",
      "[3/20] Processing m.scott@dundermifflin.com...\n",
      "üìß Email successfully delivered to: m.scott@dundermifflin.com\n",
      "[4/20] Processing s.connor@cyberdyne.io...\n",
      "üìß Email successfully delivered to: s.connor@cyberdyne.io\n",
      "[5/20] Processing satya@microsoft.com...\n",
      "üìß Email successfully delivered to: satya@microsoft.com\n",
      "[6/20] Processing arman@tech-bangla.com...\n",
      "üìß Email successfully delivered to: arman@tech-bangla.com\n",
      "[7/20] Processing d.schrute@dundermifflin.com...\n",
      "üìß Email successfully delivered to: d.schrute@dundermifflin.com\n",
      "[8/20] Processing p.parker@dailybugle.com...\n",
      "üìß Email successfully delivered to: p.parker@dailybugle.com\n",
      "[9/20] Processing tony@starkindustries.com...\n",
      "üìß Email successfully delivered to: tony@starkindustries.com\n",
      "[10/20] Processing lutfur@dhaka-solutions.net...\n",
      "üìß Email successfully delivered to: lutfur@dhaka-solutions.net\n",
      "[11/20] Processing bruce@waynetech.com...\n",
      "üìß Email successfully delivered to: bruce@waynetech.com\n",
      "[12/20] Processing p.beesly@dundermifflin.com...\n",
      "üìß Email successfully delivered to: p.beesly@dundermifflin.com\n",
      "[13/20] Processing sam@openai.com...\n",
      "üìß Email successfully delivered to: sam@openai.com\n",
      "[14/20] Processing anika@brac-it.org...\n",
      "üìß Email successfully delivered to: anika@brac-it.org\n",
      "[15/20] Processing j.wick@continental.com...\n",
      "üìß Email successfully delivered to: j.wick@continental.com\n",
      "[16/20] Processing s.holmes@221b.com...\n",
      "üìß Email successfully delivered to: s.holmes@221b.com\n",
      "[17/20] Processing tanvir@pathao.com...\n",
      "üìß Email successfully delivered to: tanvir@pathao.com\n",
      "[18/20] Processing mark@meta.com...\n",
      "üìß Email successfully delivered to: mark@meta.com\n",
      "[19/20] Processing jeb@bush-consulting.com...\n",
      "üìß Email successfully delivered to: jeb@bush-consulting.com\n",
      "[20/20] Processing h.specter@pearson-hardman.com...\n",
      "üìß Email successfully delivered to: h.specter@pearson-hardman.com\n",
      "‚úÖ Results saved to enriched_leads.csv\n",
      "üìä Generating Campaign Summary Report...\n",
      "üèÅ All Tasks Complete. Check 'enriched_leads.csv' and 'reports/campaign_summary.md'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Load Leads\n",
    "df = pd.read_csv(\"lead.csv\")\n",
    "final_results = []\n",
    "\n",
    "print(f\"üöÄ NexusAI: Processing {len(df)} leads...\")\n",
    "\n",
    "# 2. Process each lead through the Graph\n",
    "for index, row in df.iterrows():\n",
    "    lead_dict = row.to_dict()\n",
    "    \n",
    "    # Initial State for this lead\n",
    "    initial_state = {\n",
    "        \"lead_data\": lead_dict,\n",
    "        \"priority\": \"\",\n",
    "        \"priority_score\": 0,\n",
    "        \"priority_reason\": \"\",\n",
    "        \"persona\": \"\",\n",
    "        \"persona_description\": \"\",\n",
    "        \"email_subject\": \"\",\n",
    "        \"email_body\": \"\",\n",
    "        \"simulated_reply\": \"\",\n",
    "        \"response_category\": \"\",\n",
    "        \"status\": \"Pending\"\n",
    "    }\n",
    "    \n",
    "    # INVOKE LANGGRAPH\n",
    "    print(f\"[{index+1}/{len(df)}] Processing {lead_dict['Email']}...\")\n",
    "    result_state = nexus_app.invoke(initial_state)\n",
    "    \n",
    "    # Store the result\n",
    "    final_results.append(result_state)\n",
    "\n",
    "# 3. Save Enriched CSV\n",
    "# We flatten the lead_data dict back into columns for a clean CSV\n",
    "enriched_df = pd.DataFrame(final_results)\n",
    "# Flatten lead_data into separate columns\n",
    "lead_columns = pd.json_normalize(enriched_df['lead_data'])\n",
    "enriched_df = pd.concat([lead_columns, enriched_df.drop(columns=['lead_data'])], axis=1)\n",
    "\n",
    "enriched_df.to_csv(\"enriched_leads.csv\", index=False)\n",
    "print(\"‚úÖ Results saved to enriched_leads.csv\")\n",
    "\n",
    "# 4. Generate & Save Markdown Report\n",
    "print(\"üìä Generating Campaign Summary Report...\")\n",
    "report_content = generate_campaign_report(final_results)\n",
    "\n",
    "# Create reports directory if it doesn't exist\n",
    "os.makedirs(\"reports\", exist_ok=True)\n",
    "with open(\"reports/campaign_summary.md\", \"w\") as f:\n",
    "    f.write(report_content)\n",
    "\n",
    "print(\"üèÅ All Tasks Complete. Check 'enriched_leads.csv' and 'reports/campaign_summary.md'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NexusAI-Agentic-Sales-Campaign-CRM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
