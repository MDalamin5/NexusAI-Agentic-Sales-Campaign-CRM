{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd0dc3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56b25c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6dc9bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af218bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Company Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Michael</td>\n",
       "      <td>Scott</td>\n",
       "      <td>m.scott@dundermifflin.com</td>\n",
       "      <td>Dunder Mifflin</td>\n",
       "      <td>Regional Manager</td>\n",
       "      <td>Paper &amp; Distribution</td>\n",
       "      <td>10-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bruce</td>\n",
       "      <td>Wayne</td>\n",
       "      <td>bruce@waynetech.com</td>\n",
       "      <td>Wayne Enterprises</td>\n",
       "      <td>Chairman</td>\n",
       "      <td>Conglomerate</td>\n",
       "      <td>10000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Harvey</td>\n",
       "      <td>Specter</td>\n",
       "      <td>h.specter@pearson-hardman.com</td>\n",
       "      <td>Pearson Hardman</td>\n",
       "      <td>Senior Partner</td>\n",
       "      <td>Law</td>\n",
       "      <td>200-500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   First Name Last Name                          Email            Company  \\\n",
       "2     Michael     Scott      m.scott@dundermifflin.com     Dunder Mifflin   \n",
       "10      Bruce     Wayne            bruce@waynetech.com  Wayne Enterprises   \n",
       "19     Harvey   Specter  h.specter@pearson-hardman.com    Pearson Hardman   \n",
       "\n",
       "           Job Title              Industry Company Size  \n",
       "2   Regional Manager  Paper & Distribution        10-50  \n",
       "10          Chairman          Conglomerate       10000+  \n",
       "19    Senior Partner                   Law      200-500  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"lead.csv\")\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec1937dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # --- 1. INPUT DATA ---\n",
    "    lead_data: dict  # Raw data from CSV (Name, Email, Company, Job Title, etc.)\n",
    "    \n",
    "    # --- 2. QUALIFICATION (From Scorer Agent) ---\n",
    "    priority: str          # \"High\", \"Medium\", \"Low\"\n",
    "    priority_score: int    # 1 to 10 (Useful for sorting the final CSV)\n",
    "    priority_reason: str   # The \"Why\" behind the score\n",
    "    \n",
    "    # --- 3. ENRICHMENT (From Persona Agent) ---\n",
    "    persona: str           # e.g., \"The Data-Driven Executive\"\n",
    "    persona_description: str # Brief profile of their pain points\n",
    "    \n",
    "    # --- 4. OUTREACH (From Drafter Agent) ---\n",
    "    email_subject: str\n",
    "    email_body: str        # The personalized HTML/Text body\n",
    "    \n",
    "    # --- 5. SIMULATION (From Response Agents) ---\n",
    "    simulated_reply: Optional[str]   # What the AI thinks they would say back\n",
    "    response_category: Optional[str] # \"Interested\", \"Not Interested\", \"Auto-reply\"\n",
    "    \n",
    "    # --- 6. EXECUTION STATUS ---\n",
    "    status: str            # \"Sent\", \"Failed\", or \"Pending\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae9ba7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq # Switch later\n",
    "from prompts import LEAD_SCORER_SYSTEM_PROMPT, PERSONA_ENRICHER_SYSTEM_PROMPT\n",
    "from schema import LeadScore\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def get_scorer_agent():\n",
    "    # Model Setup\n",
    "    # llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0) \n",
    "    # To switch to Groq later:\n",
    "    llm = ChatGroq(model=\"qwen/qwen3-32b\", temperature=0)\n",
    "    \n",
    "    # Bind the structured output schema to the LLM\n",
    "    structured_llm = llm.with_structured_output(LeadScore)\n",
    "    \n",
    "    return structured_llm\n",
    "\n",
    "# --- THE NODE FUNCTION FOR LANGGRAPH ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a3f24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lead_scorer_node(state: AgentState):\n",
    "    lead_data = state[\"lead_data\"]\n",
    "    \n",
    "    # Format the user message with Lead details\n",
    "    user_message = f\"Lead Data: {lead_data}\"\n",
    "    \n",
    "    # Invoke the agent\n",
    "    scorer_agent = get_scorer_agent()\n",
    "    result = scorer_agent.invoke([\n",
    "        (\"system\", LEAD_SCORER_SYSTEM_PROMPT),\n",
    "        (\"human\", user_message)\n",
    "    ])\n",
    "    \n",
    "    # Update the LangGraph State\n",
    "    return {\n",
    "        \"priority\": result.priority,\n",
    "        \"priority_score\": result.score, # Added to state for more detail\n",
    "        \"priority_reason\": result.reasoning\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859e837c",
   "metadata": {},
   "source": [
    "## **Test the lead-scorer agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12218f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'priority': 'Low', 'priority_score': 3, 'priority_reason': 'The lead is a Jr. AI Engineer at a mid-sized AI Solutions company. Junior roles typically lack decision-making authority, and while the industry is relevant, the position does not indicate high budget control or partnership potential.'}\n"
     ]
    }
   ],
   "source": [
    "# Create a dummy row from your DF\n",
    "sample_lead = df.iloc[1].to_dict() # Elon Musk\n",
    "\n",
    "# Create initial state\n",
    "test_state = {\n",
    "    \"lead_data\": sample_lead,\n",
    "    \"priority\": \"\",\n",
    "    \"priority_score\": 0,\n",
    "    \"priority_reason\": \"\"\n",
    "}\n",
    "\n",
    "# Run node\n",
    "updated_state = lead_scorer_node(test_state)\n",
    "print(updated_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a13cc19",
   "metadata": {},
   "source": [
    "## **Persona Enricher Node**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f40eeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from schema import PersonaEnrichment\n",
    "\n",
    "def get_persona_agent():\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7) # Slightly higher temperature for \"Creativity\"\n",
    "    structured_llm = llm.with_structured_output(PersonaEnrichment)\n",
    "    return structured_llm\n",
    "\n",
    "# --- THE NODE FUNCTION ---\n",
    "def persona_enricher_node(state: AgentState):\n",
    "    lead_data = state[\"lead_data\"]\n",
    "    \n",
    "    user_message = f\"Lead Data: {lead_data}\"\n",
    "    \n",
    "    agent = get_persona_agent()\n",
    "    result = agent.invoke([\n",
    "        (\"system\", PERSONA_ENRICHER_SYSTEM_PROMPT),\n",
    "        (\"human\", user_message)\n",
    "    ])\n",
    "    \n",
    "    # Update the LangGraph State\n",
    "    return {\n",
    "        \"persona\": result.persona,\n",
    "        \"persona_description\": result.persona_description\n",
    "        # Note: You can also store key_motivations if you add it to AgentState\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da2f93f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priority: Low\n",
      "Persona: The Efficiency Champion\n",
      "Description: A result-driven manager focused on optimizing team performance and resource allocation. They are constantly seeking ways to enhance productivity while minimizing costs and ensuring staff satisfaction in a competitive market.\n"
     ]
    }
   ],
   "source": [
    "# 1. Reset your test state\n",
    "test_state = {\n",
    "    \"lead_data\": df.iloc[2].to_dict(), # Using the Jr. AI Engineer row\n",
    "    \"priority\": \"\",\n",
    "    \"priority_score\": 0,\n",
    "    \"priority_reason\": \"\",\n",
    "    \"persona\": \"\",\n",
    "    \"persona_description\": \"\"\n",
    "}\n",
    "\n",
    "# 2. Run Scorer and UPDATE the dictionary (Don't overwrite it)\n",
    "scorer_results = lead_scorer_node(test_state)\n",
    "test_state.update(scorer_results) \n",
    "\n",
    "# Now test_state has BOTH lead_data AND the priority results\n",
    "\n",
    "# 3. Now run the Enricher\n",
    "persona_results = persona_enricher_node(test_state)\n",
    "test_state.update(persona_results)\n",
    "\n",
    "# 4. Check the results\n",
    "print(f\"Priority: {test_state['priority']}\")\n",
    "print(f\"Persona: {test_state['persona']}\")\n",
    "print(f\"Description: {test_state['persona_description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4868a9",
   "metadata": {},
   "source": [
    "## **Draft a ostrich Email**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24ac2436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import OUTREACH_DRAFTER_SYSTEM_PROMPT\n",
    "from schema import EmailDraft\n",
    "\n",
    "def get_drafter_agent():\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.8) # Higher temperature for creative writing\n",
    "    structured_llm = llm.with_structured_output(EmailDraft)\n",
    "    return structured_llm\n",
    "\n",
    "# --- THE NODE FUNCTION ---\n",
    "def outreach_drafter_node(state: AgentState):\n",
    "    lead_data = state[\"lead_data\"]\n",
    "    priority = state[\"priority\"]\n",
    "    persona = state[\"persona\"]\n",
    "    \n",
    "    # Combine context for the agent\n",
    "    context = f\"\"\"\n",
    "    Lead: {lead_data['First Name']} {lead_data['Last Name']}\n",
    "    Role: {lead_data['Job Title']} at {lead_data['Company']}\n",
    "    Priority Level: {priority}\n",
    "    Buyer Persona: {persona}\n",
    "    \"\"\"\n",
    "    \n",
    "    agent = get_drafter_agent()\n",
    "    result = agent.invoke([\n",
    "        (\"system\", OUTREACH_DRAFTER_SYSTEM_PROMPT),\n",
    "        (\"human\", f\"Draft a personalized email for this lead:\\n{context}\")\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"email_subject\": result.subject,\n",
    "        \"email_body\": result.body\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dccc601a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Quick question about streamlining Dunder Mifflin's processes\n",
      "------------------------------\n",
      "Hi Michael,<br><br>As the Regional Manager at Dunder Mifflin, I know you're always on the lookout for ways to boost efficiency. That's why I wanted to share how NexusAI can help you automate tedious tasks, saving your team valuable time and reducing manual work.<br><br>Open to a 5-minute chat? I'd love to explore how we can support your goals.<br><br>Best,<br>NexusAI Growth Team\n"
     ]
    }
   ],
   "source": [
    "# Continue from your previous 'test_state'\n",
    "drafter_results = outreach_drafter_node(test_state)\n",
    "test_state.update(drafter_results)\n",
    "\n",
    "print(f\"Subject: {test_state['email_subject']}\")\n",
    "print(\"-\" * 30)\n",
    "print(test_state['email_body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebd9f2a",
   "metadata": {},
   "source": [
    "## **SMTP Sender Node**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b25d5bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "def sender_node(state: AgentState):\n",
    "    \"\"\"\n",
    "    Physically sends the drafted email to MailHog via SMTP.\n",
    "    \"\"\"\n",
    "    # 1. Get data from state\n",
    "    lead_email = state[\"lead_data\"][\"Email\"]\n",
    "    subject = state[\"email_subject\"]\n",
    "    body = state[\"email_body\"]\n",
    "    \n",
    "    # 2. Setup SMTP Config\n",
    "    # If running notebook locally: use \"localhost\"\n",
    "    # If running inside Docker later: use \"mailhog\"\n",
    "    SMTP_HOST = \"localhost\" \n",
    "    SMTP_PORT = 1025\n",
    "    SENDER_EMAIL = \"outreach@nexusai.com\"\n",
    "\n",
    "    # 3. Create the MIME Message\n",
    "    message = MIMEMultipart()\n",
    "    message[\"From\"] = SENDER_EMAIL\n",
    "    message[\"To\"] = lead_email\n",
    "    message[\"Subject\"] = subject\n",
    "    \n",
    "    # Use \"html\" type because our drafter agent uses <br> tags\n",
    "    message.attach(MIMEText(body, \"html\"))\n",
    "\n",
    "    # 4. Attempt to send\n",
    "    try:\n",
    "        with smtplib.SMTP(SMTP_HOST, SMTP_PORT) as server:\n",
    "            server.sendmail(SENDER_EMAIL, [lead_email], message.as_string())\n",
    "        \n",
    "        print(f\"üìß Email successfully delivered to: {lead_email}\")\n",
    "        return {\"status\": \"Sent\"}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå SMTP Error: {e}\")\n",
    "        return {\"status\": f\"Failed: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ced9e1",
   "metadata": {},
   "source": [
    "## **Test the mail**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "081139e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìß Email successfully delivered to: m.scott@dundermifflin.com\n",
      "Final Status: Sent\n"
     ]
    }
   ],
   "source": [
    "# Continue from your test_state (which has the subject and body from the previous cell)\n",
    "sender_results = sender_node(test_state)\n",
    "test_state.update(sender_results)\n",
    "\n",
    "print(f\"Final Status: {test_state['status']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NexusAI-Agentic-Sales-Campaign-CRM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
